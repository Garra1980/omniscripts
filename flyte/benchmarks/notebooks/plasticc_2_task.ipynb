{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PLAsTiCC benchmark - ML model training with xgboost\n",
    "## `https://www.kaggle.com/c/PLAsTiCC-2018/data`\n",
    "\n",
    "### The goal is to measure the total execution time of flytekit workflow: [Workflow execution cell](#execution_cell)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import time\n",
    "\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from timeit import default_timer as timer\n",
    "from dataclasses import dataclass\n",
    "import typing\n",
    "from flytekit import Resources, task, workflow, dynamic\n",
    "from flytekit.types.file import FlyteFile\n",
    "from flytekit.types.schema import FlyteSchema\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import logging\n",
    "from flytekit.loggers import logger\n",
    "\n",
    "logger.setLevel(level=logging.WARN)\n",
    "logger.getEffectiveLevel"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Logger.getEffectiveLevel of <Logger flytekit (WARNING)>>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "DATASET_PATH = \"https://modin-datasets.s3.amazonaws.com/plasticc/\"  # path do folder is to write\n",
    "\n",
    "ETL_KEYS = [\"t_readcsv\", \"t_etl\", \"t_connect\"]\n",
    "ML_KEYS = [\"t_train_test_split\", \"t_dmatrix\", \"t_training\", \"t_infer\", \"t_ml\"]\n",
    "\n",
    "\n",
    "COLUMNS_NAMES = [\n",
    "    \"object_id\",\n",
    "    \"ra\",\n",
    "    \"decl\",\n",
    "    \"gal_l\",\n",
    "    \"gal_b\",\n",
    "    \"ddf\",\n",
    "    \"hostgal_specz\",\n",
    "    \"hostgal_photoz\",\n",
    "    \"hostgal_photoz_err\",\n",
    "    \"distmod\",\n",
    "    \"mwebv\",\n",
    "    \"target\",\n",
    "]\n",
    "\n",
    "\n",
    "DTYPES = OrderedDict(\n",
    "    [\n",
    "        (\"object_id\", \"int\"),\n",
    "        (\"mjd\", \"float\"),\n",
    "        (\"passband\", \"int\"),\n",
    "        (\"flux\", \"float\"),\n",
    "        (\"flux_err\", \"float\"),\n",
    "        (\"detected\", \"int\"),\n",
    "    ]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def split(X, y, test_size=0.1, stratify=None, random_state=None):\n",
    "    t0 = timer()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=stratify, random_state=random_state\n",
    "    )\n",
    "    split_time = timer() - t0\n",
    "\n",
    "    return (X_train, y_train, X_test, y_test), split_time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def ravel_column_names(cols):\n",
    "    d0 = cols.get_level_values(0)\n",
    "    d1 = cols.get_level_values(1)\n",
    "    return [\"%s_%s\" % (i, j) for i, j in zip(d0, d1)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "def load_data_pandas(dataset_path, dtypes, meta_dtypes):\n",
    "    train = pd.read_csv(f\"{dataset_path}training_set.csv\", dtype=dtypes)\n",
    "\n",
    "    test = pd.read_csv(f\"{dataset_path}test_set_sample.csv.gz\", compression='gzip')\n",
    "\n",
    "    train_meta = pd.read_csv(f\"{dataset_path}training_set_metadata.csv\", dtype=meta_dtypes)\n",
    "    target = meta_dtypes.pop(\"target\")\n",
    "    test_meta = pd.read_csv(f\"{dataset_path}test_set_metadata.csv\", dtype=meta_dtypes)\n",
    "    meta_dtypes[\"target\"] = target\n",
    "\n",
    "    return train, train_meta, test, test_meta"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def etl_cpu_pandas(df, df_meta, etl_times):\n",
    "    t_etl_start = timer()\n",
    "\n",
    "    # workaround for both Modin_on_ray and Modin_on_hdk modes. Eventually this should be fixed\n",
    "    df[\"flux_ratio_sq\"] = (df[\"flux\"] / df[\"flux_err\"]) * (\n",
    "        df[\"flux\"] / df[\"flux_err\"]\n",
    "    )  # np.power(df[\"flux\"] / df[\"flux_err\"], 2.0)\n",
    "    df[\"flux_by_flux_ratio_sq\"] = df[\"flux\"] * df[\"flux_ratio_sq\"]\n",
    "\n",
    "    aggs = {\n",
    "        \"passband\": [\"mean\"],\n",
    "        \"flux\": [\"min\", \"max\", \"mean\", \"skew\"],\n",
    "        \"flux_err\": [\"min\", \"max\", \"mean\"],\n",
    "        \"detected\": [\"mean\"],\n",
    "        \"mjd\": [\"max\", \"min\"],\n",
    "        \"flux_ratio_sq\": [\"sum\"],\n",
    "        \"flux_by_flux_ratio_sq\": [\"sum\"],\n",
    "    }\n",
    "    agg_df = df.groupby(\"object_id\", sort=False).agg(aggs)\n",
    "\n",
    "    agg_df.columns = ravel_column_names(agg_df.columns)\n",
    "\n",
    "    agg_df[\"flux_diff\"] = agg_df[\"flux_max\"] - agg_df[\"flux_min\"]\n",
    "    agg_df[\"flux_dif2\"] = agg_df[\"flux_diff\"] / agg_df[\"flux_mean\"]\n",
    "    agg_df[\"flux_w_mean\"] = agg_df[\"flux_by_flux_ratio_sq_sum\"] / agg_df[\"flux_ratio_sq_sum\"]\n",
    "    agg_df[\"flux_dif3\"] = agg_df[\"flux_diff\"] / agg_df[\"flux_w_mean\"]\n",
    "    agg_df[\"mjd_diff\"] = agg_df[\"mjd_max\"] - agg_df[\"mjd_min\"]\n",
    "\n",
    "    agg_df = agg_df.drop([\"mjd_max\", \"mjd_min\"], axis=1)\n",
    "\n",
    "    agg_df = agg_df.reset_index()\n",
    "\n",
    "    df_meta = df_meta.drop([\"ra\", \"decl\", \"gal_l\", \"gal_b\"], axis=1)\n",
    "\n",
    "    df_meta = df_meta.merge(agg_df, on=\"object_id\", how=\"left\")\n",
    "\n",
    "    _ = df_meta.shape\n",
    "    etl_times[\"t_etl\"] += timer() - t_etl_start\n",
    "\n",
    "    return df_meta"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def split_step(train_final, test_final):\n",
    "\n",
    "    X = train_final.drop([\"object_id\", \"target\"], axis=1).values\n",
    "    Xt = test_final.drop([\"object_id\"], axis=1).values\n",
    "\n",
    "    y = train_final[\"target\"]\n",
    "    assert X.shape[1] == Xt.shape[1]\n",
    "    classes = sorted(y.unique())\n",
    "\n",
    "    class_weights = {c: 1 for c in classes}\n",
    "    class_weights.update({c: 2 for c in [64, 15]})\n",
    "\n",
    "    lbl = LabelEncoder()\n",
    "    y = lbl.fit_transform(y)\n",
    "\n",
    "    (X_train, y_train, X_test, y_test), split_time = split(\n",
    "        X, y, test_size=0.1, stratify=y, random_state=126\n",
    "    )\n",
    "\n",
    "    return (X_train, y_train, X_test, y_test, Xt, classes, class_weights), split_time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def multi_weighted_logloss(y_true, y_preds, classes, class_weights):\n",
    "    \"\"\"\n",
    "    refactor from\n",
    "    @author olivier https://www.kaggle.com/ogrellier\n",
    "    multi logloss for PLAsTiCC challenge\n",
    "    \"\"\"\n",
    "    y_p = y_preds.reshape(y_true.shape[0], len(classes), order=\"F\")\n",
    "    y_ohe = pd.get_dummies(y_true)\n",
    "    y_p = np.clip(a=y_p, a_min=1e-15, a_max=1 - 1e-15)\n",
    "    y_p_log = np.log(y_p)\n",
    "    y_log_ones = np.sum(y_ohe.values * y_p_log, axis=0)\n",
    "    nb_pos = y_ohe.sum(axis=0).values.astype(float)\n",
    "    class_arr = np.array([class_weights[k] for k in sorted(class_weights.keys())])\n",
    "    y_w = y_log_ones * class_arr / nb_pos\n",
    "\n",
    "    loss = -np.sum(y_w) / np.sum(class_arr)\n",
    "    return loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def xgb_multi_weighted_logloss(y_predicted, y_true, classes, class_weights):\n",
    "    loss = multi_weighted_logloss(y_true.get_label(), y_predicted, classes, class_weights)\n",
    "    return \"wloss\", loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "@task\n",
    "def etl_all_pandas(\n",
    "    dataset_path: str,\n",
    "    columns_names: typing.List[str],\n",
    "    dtypes: typing.Dict[\n",
    "        str, str\n",
    "    ],  # types OrderedDict, pandas.Series, class 'type' are not supported!!!\n",
    "    # meta_dtypes: typing.Dict[str, type],\n",
    "    etl_keys: typing.List[str],\n",
    ") -> (pd.DataFrame, pd.DataFrame, typing.Dict[str, float]):\n",
    "    dtypes = dict(zip(dtypes.keys(), list(map(eval, dtypes.values()))))\n",
    "\n",
    "    meta_dtypes = [int] + [float] * 4 + [int] + [float] * 5 + [int]\n",
    "    meta_dtypes = OrderedDict(\n",
    "        [(columns_names[i], meta_dtypes[i]) for i in range(len(meta_dtypes))]\n",
    "    )\n",
    "\n",
    "    etl_times = {key: 0.0 for key in etl_keys}\n",
    "\n",
    "    t0 = timer()\n",
    "    train, train_meta, test, test_meta = load_data_pandas(\n",
    "        dataset_path=dataset_path, dtypes=dtypes, meta_dtypes=meta_dtypes\n",
    "    )\n",
    "    etl_times[\"t_readcsv\"] += timer() - t0\n",
    "\n",
    "    # update etl_times\n",
    "    train_final = etl_cpu_pandas(train, train_meta, etl_times)\n",
    "    test_final = etl_cpu_pandas(test, test_meta, etl_times)\n",
    "\n",
    "    return train_final, test_final, etl_times"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "@task\n",
    "def ml(\n",
    "    train_final: pd.DataFrame, test_final: pd.DataFrame, ml_keys: typing.List[str]\n",
    ") -> typing.Dict[str, float]:\n",
    "    ml_times = {key: 0.0 for key in ml_keys}\n",
    "\n",
    "    (\n",
    "        (X_train, y_train, X_test, y_test, Xt, classes, class_weights),\n",
    "        ml_times[\"t_train_test_split\"],\n",
    "    ) = split_step(train_final, test_final)\n",
    "\n",
    "    #     hard_code: cpu_params cannot be an input, cause values are not homogeneous\n",
    "    cpu_params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"nthread\": 16,\n",
    "        \"num_class\": 14,\n",
    "        \"max_depth\": 7,\n",
    "        \"silent\": 1,\n",
    "        \"subsample\": 0.7,\n",
    "        \"colsample_bytree\": 0.7,\n",
    "    }\n",
    "\n",
    "    func_loss = partial(xgb_multi_weighted_logloss, classes=classes, class_weights=class_weights)\n",
    "\n",
    "    t_ml_start = timer()\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    dvalid = xgb.DMatrix(data=X_test, label=y_test)\n",
    "    dtest = xgb.DMatrix(data=Xt)\n",
    "    ml_times[\"t_dmatrix\"] += timer() - t_ml_start\n",
    "\n",
    "    watchlist = [(dvalid, \"eval\"), (dtrain, \"train\")]\n",
    "\n",
    "    t0 = timer()\n",
    "    clf = xgb.train(\n",
    "        cpu_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=60,\n",
    "        evals=watchlist,\n",
    "        feval=func_loss,\n",
    "        early_stopping_rounds=10,\n",
    "        verbose_eval=1000,\n",
    "    )\n",
    "    ml_times[\"t_training\"] += timer() - t0\n",
    "\n",
    "    t0 = timer()\n",
    "    yp = clf.predict(dvalid)\n",
    "    ml_times[\"t_infer\"] += timer() - t0\n",
    "\n",
    "    cpu_loss = multi_weighted_logloss(y_test, yp, classes, class_weights)\n",
    "\n",
    "    t0 = timer()\n",
    "    ysub = clf.predict(dtest)  # noqa: F841 (unused variable)\n",
    "    ml_times[\"t_infer\"] += timer() - t0\n",
    "\n",
    "    ml_times[\"t_ml\"] = timer() - t_ml_start\n",
    "\n",
    "    print(\"validation cpu_loss:\", cpu_loss)\n",
    "\n",
    "    return ml_times"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "@workflow\n",
    "def plasticc_ml_wf(\n",
    "    dataset_path: str = DATASET_PATH,\n",
    "    columns_names: typing.List[str] = COLUMNS_NAMES,\n",
    "    dtypes: typing.Dict[str, str] = DTYPES,\n",
    "    etl_keys: typing.List[str] = ETL_KEYS,\n",
    ") -> typing.Dict[str, float]:\n",
    "    train_final, test_final, etl_times = etl_all_pandas(\n",
    "        dataset_path=dataset_path, columns_names=columns_names, dtypes=dtypes, etl_keys=ETL_KEYS\n",
    "    )\n",
    "    return ml(train_final=train_final, test_final=test_final, ml_keys=ML_KEYS)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## <a id='execution_cell'>Workflow execution</a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "%%time\n",
    "\n",
    "plasticc_ml_wf()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[19:04:39] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[19:04:39] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\teval-mlogloss:1.74186\teval-wloss:0.28312\ttrain-mlogloss:1.65428\ttrain-wloss:0.20831\n",
      "[59]\teval-mlogloss:0.84347\teval-wloss:5.47821\ttrain-mlogloss:0.09341\ttrain-wloss:0.00000\n",
      "validation cpu_loss: 1.2229486042289204\n",
      "CPU times: user 1min 5s, sys: 6.02 s, total: 1min 11s\n",
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'t_train_test_split': 0.004123592749238014,\n",
       " 't_dmatrix': 0.5328213288448751,\n",
       " 't_training': 1.4048717538826168,\n",
       " 't_infer': 2.20736221736297,\n",
       " 't_ml': 4.146535341627896}"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "0c378adb69cb96bbe68816dc4fb8432a5cde97ca5454a9f60177648631096938"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
